{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b92270",
   "metadata": {},
   "source": [
    "ft-make data work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd445b2",
   "metadata": {},
   "source": [
    "input\n",
    "\n",
    "<user>what is the capital of France?</user>\n",
    "<assistant>Paris</assistant>\n",
    "<user>what about Spain?</user>\n",
    "<assistant>Madid</assistant>\n",
    "<user>Germany?</user>\n",
    "\n",
    "target output\n",
    "berlin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609e2a3",
   "metadata": {},
   "source": [
    "Input Alice has 3 apples and buys 2 more. How many now?\n",
    "\n",
    "Target Output\n",
    "\n",
    "<think> Start with 3. Buys 2 ⇒ 3+2=5. </think>\n",
    "\n",
    "<answer>5</answer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d06ae5",
   "metadata": {},
   "source": [
    "Input \n",
    "Carly has 8 apples and buys 2 more, but then sells 5 to the local baker. How many now?\n",
    "\n",
    "Model Output \n",
    "8+2-5=5 \n",
    "Answer: 5\n",
    "\n",
    "Grader \n",
    "Correct: +1 \n",
    "Shows work: +1 \n",
    "Total reward (score): +2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f41001",
   "metadata": {},
   "source": [
    "Input\n",
    "Greet politely\n",
    "\n",
    "Model Output\n",
    "Hi there! How are you?\n",
    "\n",
    "Grader\n",
    "High score on politeness: +1\n",
    "High score on enthusiasm: +1\n",
    "High score on engagement: +1\n",
    "Total reward (score): +3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14f315",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('openai','main')\n",
    "train = dataset['train']\n",
    "test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde8872",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer(text)\n",
    "\n",
    "output_text = tokenizer.decode(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4578d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#from probabilities to next token id\n",
    "\n",
    "model.generate(**ids) #greedy selection\n",
    "\n",
    "model.generate(**ids,do_sample=true,temperature) #sample\n",
    "# temperature = 0 时 就相当于greedy selection\n",
    "\n",
    "#beam search\n",
    "\n",
    "model.generate(**ids , num_beams=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb4e1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "AutoTokenizer.from_pretrained(module_name)(prompt_batch , padding=True)['input_ids']\n",
    "\n",
    "\n",
    "tensor([[0,  0,  2640,   3073,    418,    3221,  21142],\n",
    "        [0,  0,  3073,    418,   3221,    21142,    30],\n",
    "        [0,  0,     0,      0,   2640,    3073,    418]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加掩码算损失\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index = -100) #遇到数字-100 直接跳过\n",
    "\n",
    "logits = torch.randn(1,6,1000) # batch_size seq_len vocab_size\n",
    "\n",
    "labels = torch.tensor([[-100, -100, -100,  -100,  45,  982]])\n",
    "\n",
    "loss = loss_fn(logits.view(-1,1000),  labels.view(-1))\n",
    "#.view()  重塑张量形状 \n",
    "# view(-1请pytorch自行计算剩下的维度合并起来时多少,词表大小)处理输出logits\n",
    "#view(-1 把所有元素拉成一排)处理标签\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = SFTConfig(completion_only_loss = True , ...)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model_name,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate = 2e-6,\n",
    "    weight_decay = 0.01,\n",
    "    per_device_train_batch_size = 20,\n",
    "    per_device_eval_batch_size = 20,\n",
    "    num_train_epochs = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c96d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)           # 为当前 GPU 设置种子\n",
    "    torch.cuda.manual_seed_all(seed)       # 为所有 GPU 设置种子（多卡训练）\n",
    "    \n",
    "    # 强制 CuDNN 使用确定性算法（会让训练变慢，但保证结果完全一致）\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be73d65",
   "metadata": {},
   "source": [
    "固定随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import LoraModel , LoraConfig\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type = \"SEQ_2_SEQ_LM\",\n",
    "    r = 8,\n",
    "    lora_alpha = 32,\n",
    "    target_modules = [\"q\" , \"v\"]\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "lora_model = LoraModel(model,config,\"default\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
