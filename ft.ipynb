{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b92270",
   "metadata": {},
   "source": [
    "ft-make data work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd445b2",
   "metadata": {},
   "source": [
    "input\n",
    "\n",
    "<user>what is the capital of France?</user>\n",
    "<assistant>Paris</assistant>\n",
    "<user>what about Spain?</user>\n",
    "<assistant>Madid</assistant>\n",
    "<user>Germany?</user>\n",
    "\n",
    "target output\n",
    "berlin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609e2a3",
   "metadata": {},
   "source": [
    "Input Alice has 3 apples and buys 2 more. How many now?\n",
    "\n",
    "Target Output\n",
    "\n",
    "<think> Start with 3. Buys 2 ⇒ 3+2=5. </think>\n",
    "\n",
    "<answer>5</answer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d06ae5",
   "metadata": {},
   "source": [
    "Input \n",
    "Carly has 8 apples and buys 2 more, but then sells 5 to the local baker. How many now?\n",
    "\n",
    "Model Output \n",
    "8+2-5=5 \n",
    "Answer: 5\n",
    "\n",
    "Grader \n",
    "Correct: +1 \n",
    "Shows work: +1 \n",
    "Total reward (score): +2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f41001",
   "metadata": {},
   "source": [
    "Input\n",
    "Greet politely\n",
    "\n",
    "Model Output\n",
    "Hi there! How are you?\n",
    "\n",
    "Grader\n",
    "High score on politeness: +1\n",
    "High score on enthusiasm: +1\n",
    "High score on engagement: +1\n",
    "Total reward (score): +3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('openai','main')\n",
    "train = dataset['train']\n",
    "test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(text)\n",
    "\n",
    "output_text = tokenizer.decode(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from probabilities to next token id\n",
    "\n",
    "model.generate(**ids) #greedy selection\n",
    "\n",
    "model.generate(**ids,do_sample=true,temperature) #sample\n",
    "# temperature = 0 时 就相当于greedy selection\n",
    "\n",
    "#beam search\n",
    "\n",
    "model.generate(**ids , num_beams=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoTokenizer.from_pretrained(module_name)(prompt_batch , padding=True)['input_ids']\n",
    "\n",
    "\n",
    "tensor([[0,  0,  2640,   3073,    418,    3221,  21142],\n",
    "        [0,  0,  3073,    418,   3221,    21142,    30],\n",
    "        [0,  0,     0,      0,   2640,    3073,    418]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加掩码算损失\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index = -100) #遇到数字-100 直接跳过\n",
    "\n",
    "logits = torch.randn(1,6,1000) # batch_size seq_len vocab_size\n",
    "\n",
    "labels = torch.tensor([[-100, -100, -100,  -100,  45,  982]])\n",
    "\n",
    "loss = loss_fn(logits.view(-1,1000),  labels.view(-1))\n",
    "#.view()  重塑张量形状 \n",
    "# view(-1请pytorch自行计算剩下的维度合并起来时多少,词表大小)处理输出logits\n",
    "#view(-1 把所有元素拉成一排)处理标签\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = SFTConfig(completion_only_loss = True , ...)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model_name,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate = 2e-6,\n",
    "    weight_decay = 0.01,\n",
    "    per_device_train_batch_size = 20,\n",
    "    per_device_eval_batch_size = 20,\n",
    "    num_train_epochs = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c96d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)           # 为当前 GPU 设置种子\n",
    "    torch.cuda.manual_seed_all(seed)       # 为所有 GPU 设置种子（多卡训练）\n",
    "    \n",
    "    # 强制 CuDNN 使用确定性算法（会让训练变慢，但保证结果完全一致）\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be73d65",
   "metadata": {},
   "source": [
    "固定随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import LoraModel , LoraConfig\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type = \"SEQ_2_SEQ_LM\",\n",
    "    r = 8,\n",
    "    lora_alpha = 32,\n",
    "    target_modules = [\"q\" , \"v\"]\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "lora_model = LoraModel(model,config,\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fbfc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifiers in GRPO and DeepSeek models\n",
    "\n",
    "def math_reward(response, correct_answer):\n",
    "    if (extract_final_answer(response) == correct_answer):\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def format_reward(response):\n",
    "    if (\"<think>\" in response and \"</think>\" in response):\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def language_consistency_reward(response):\n",
    "    if consistent_language(response):\n",
    "        return 1.0\n",
    "    else:\n",
    "        return -0.5\n",
    "    \n",
    "\n",
    "def combined_reward(response, correct_answer):\n",
    "    accuracy = math_reward(response, correct_answer)\n",
    "    format_check = format_reward(response)\n",
    "    language_check = language_consistency_reward(response)\n",
    "\n",
    "    return accuracy + format_check + language_check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dab3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predicted == correct_answer :\n",
    "    reward = 1.0\n",
    "else:\n",
    "    relative_error = abs(predicted - correct_answer)/correct_answer\n",
    "\n",
    "    if relative_error < 0.01:\n",
    "        reward = 1.0\n",
    "    elif relative_error < 0.1:\n",
    "        reward = 0.8\n",
    "    elif relative_error < 0.3:\n",
    "        reward = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRPO_config = GRPOConfig(\n",
    "    num_generations = 12\n",
    "    temperature = 0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adeac01",
   "metadata": {},
   "source": [
    "temperature helps you sample different outputs,per input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward = sum(group_rewards) / len(group_rewards)\n",
    "normalized_rewards = [r - mean_reward for r in group_rewards]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fe50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_rewards(prompts, completions):\n",
    "    #同一个问题prompt 对应 不同回答completions\n",
    "\n",
    "    unique_prompts = list(set(prompts))\n",
    "\n",
    "    for i, prompt in enumerate(unique_prompts): #unique_prompts是prompts进行了去重操作\n",
    "        prompt_indices = [i for i,p in enumerate(prompts) if p == prompt]\n",
    "        group_outputs = [completions[i] for i in prompt_indices] \n",
    "    for j,out in enumerate(group_outputs):\n",
    "        reward = reward_model.compute_reward(out,correct_out,prompt)\n",
    "        group_rewards.append(reward)\n",
    "\n",
    "    mean_reward = sum(group_rewards) / len(group_rewards)\n",
    "    variance = sum((r - mean_reward) ** 2 for r in group_rewards)/len(group_rewards)\n",
    "    std_reward = math.sqrt(variance)\n",
    "    normalized_rewards = [(r - mean_reward)/(std_reward + 1e-8) for r in group_rewards]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model ,\n",
    "    reward_funcs = compute_rewards, #奖励函数\n",
    "    args = GRPO_config,\n",
    "    train_dataset = eval_dataset,\n",
    "    processing_class = tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47180c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite: \"debug_search_api_v1\"    #held out RL test env\n",
    "version: \"1.0.0\"        #env版本\n",
    "global_seed: 424242         #fixed RNG for reproducibility\n",
    "time_fixed_utc:\"2026-01-21T12:00:00Z\"       #freeze time inside the env\n",
    "\n",
    "llm:\n",
    "    model:\"policy-llm@sha256:POLICY_SHA\"  #指定模型 使用哈希 比特级一致\n",
    "    prompt_template_sha:\"SHA_PROMPT_V1\"  #指定prompt模板\n",
    "    tokenizer_sha:\"SHA_TOKENIZER_V1\"    #指定tokenizer\n",
    "    decoding:       #deterministic decoding\n",
    "        temperature: 0.0    #greedy search\n",
    "        top_p: 0.0      #greedy search 配合temperature使用\n",
    "        top_k: 0        #greedy search 配合temperature使用\n",
    "        max_new_tokens: 512 #生成长度限制 控制显存和时间 防止进入死循环\n",
    "    determinism:\n",
    "        cuda_deterministic: True  #确保cuda操作确定性\n",
    "        cuda_benchmark: False\n",
    "\n",
    "\n",
    "tools:\n",
    "    - name: \"search_api\"\n",
    "      interface: \"openapi\" #工具接口标准\n",
    "      mode: \"replay\"       #工具使用模式 replay回放\n",
    "      fixture: \"fixtures/search_api_v3.json\"    #指定“剧本”文件\n",
    "      seed: 1337\n",
    "    - name: \"my_codebase\"\n",
    "      interface: \"filesystem\" #工具接口标准\n",
    "      mode: \"snapshot\"\n",
    "      snapshot_sha: \"GIT_SHA_CODEBASE_V3\"\n",
    "      mount_path: \"/mnt/code\"\n",
    "\n",
    "verifiers:      # programmatic graders\n",
    "    unit_tests_v2:\n",
    "        type: \"code_tests\"\n",
    "        config: \"verifiers/unit_tests_v2.yaml\"  # which tests to run/expect\n",
    "    api_version_checker_v1:\n",
    "        type: \"string_match\"\n",
    "        expected_version: \"3.2.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316acdf",
   "metadata": {},
   "source": [
    "RL env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa68987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "embedding_model = SetenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "embeddings = embedding_model.encode(texts)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3 , random_state = 42)\n",
    "cluster_labels = kmeans.fit_predict(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40764bbc",
   "metadata": {},
   "source": [
    "聚类进行error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f0a2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2183637626.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    prompt = f\"\"\"Analyze this math error and categorize it:\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "EEROR_CATEGORIES = {\n",
    "    \"calculation_error\",\n",
    "    \"reasoning_error\",\n",
    "    \"incomplete_solution\",\n",
    "    \"format_error\",\n",
    "    \"other\"\n",
    "}\n",
    "\n",
    "prompt = f\"\"\"Analyze this math error and categorize it:\n",
    "PROBLEM: {question}...\n",
    "CORRECT: {correct_answer}\n",
    "PREDICTED: {predicted_answer}\n",
    "Choose ONE category: {', '.join(ERROR_CATEGORIES)}\n",
    "Respond with just the category name.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165c29c",
   "metadata": {},
   "source": [
    "利用python自动填表，生成给LLM的prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a2be6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
